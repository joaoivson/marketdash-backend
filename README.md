# MarketDash Backend - SaaS de AnÃ¡lise de Dados

Backend completo para um SaaS de anÃ¡lise de dados, focado em ingestÃ£o de CSV, armazenamento acumulativo, agregaÃ§Ãµes analÃ­ticas e exposiÃ§Ã£o de APIs para consumo por um frontend React.

## ğŸš€ Tecnologias

- **Python 3.11+**
- **FastAPI** - Framework web moderno e rÃ¡pido
- **SQLAlchemy 2.0** - ORM para PostgreSQL
- **PostgreSQL** - Banco de dados relacional
- **Pandas** - Processamento e validaÃ§Ã£o de CSV
- **Pydantic** - ValidaÃ§Ã£o de dados e schemas
- **JWT** - AutenticaÃ§Ã£o baseada em tokens
- **Docker & Docker Compose** - ContainerizaÃ§Ã£o

## ğŸ“ Estrutura do Projeto

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                 # AplicaÃ§Ã£o FastAPI principal
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py           # ConfiguraÃ§Ãµes e variÃ¡veis de ambiente
â”‚   â”‚   â””â”€â”€ security.py         # JWT e hash de senhas
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ session.py          # SessÃ£o do banco de dados
â”‚   â”‚   â””â”€â”€ base.py             # Base declarativa SQLAlchemy
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ user.py             # Modelo de usuÃ¡rio
â”‚   â”‚   â”œâ”€â”€ dataset.py          # Modelo de dataset (upload)
â”‚   â”‚   â”œâ”€â”€ dataset_row.py      # Modelo de linhas do CSV
â”‚   â”‚   â””â”€â”€ subscription.py    # Modelo de assinatura
â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”œâ”€â”€ user.py             # Schemas Pydantic para usuÃ¡rios
â”‚   â”‚   â”œâ”€â”€ dataset.py          # Schemas Pydantic para datasets
â”‚   â”‚   â””â”€â”€ dashboard.py        # Schemas Pydantic para dashboard
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ csv_service.py      # ServiÃ§o de processamento de CSV
â”‚   â”‚   â””â”€â”€ dashboard_service.py # ServiÃ§o de analytics e agregaÃ§Ãµes
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ deps.py             # DependÃªncias (autenticaÃ§Ã£o)
â”‚   â”‚   â””â”€â”€ routes/
â”‚   â”‚       â”œâ”€â”€ auth.py         # Endpoints de autenticaÃ§Ã£o
â”‚   â”‚       â”œâ”€â”€ datasets.py     # Endpoints de datasets
â”‚   â”‚       â””â”€â”€ dashboard.py    # Endpoints de dashboard
â”‚   â””â”€â”€ utils/
â”œâ”€â”€ tests/
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ—„ï¸ Modelo de Dados

### UsuÃ¡rios (users)
- `id`: ID Ãºnico
- `email`: Email Ãºnico do usuÃ¡rio
- `hashed_password`: Senha criptografada
- `is_active`: Status ativo/inativo
- `created_at`: Data de criaÃ§Ã£o

### Datasets (datasets)
- `id`: ID Ãºnico
- `user_id`: ID do usuÃ¡rio proprietÃ¡rio
- `filename`: Nome do arquivo CSV original
- `uploaded_at`: Data de upload

### Linhas do Dataset (dataset_rows)
- `id`: ID unico
- `dataset_id`: ID do dataset
- `user_id`: ID do usuario proprietario
- `date`: Data da transacao (normalizada)
- `transaction_date`: Data original (quando aplicavel)
- `time`: Hora da transacao (quando aplicavel)
- `product`: Produto normalizado
- `product_name`: Nome original do produto (quando aplicavel)
- `platform`: Plataforma/origem
- `status`: Status da transacao
- `category`: Categoria
- `sub_id1`: Sub ID
- `mes_ano`: Mes/ano de referencia
- `gross_value`: Valor bruto
- `commission_value`: Valor de comissao
- `net_value`: Valor liquido
- `quantity`: Quantidade
- `revenue`: Receita
- `cost`: Custo
- `commission`: Comissao
- `profit`: Lucro (calculado: revenue - cost - commission)
- `raw_data`: JSON bruto da linha (quando aplicavel)

**Ãndices criados para otimizaÃ§Ã£o:**
- `user_id`
- `date`
- `product`
- `(user_id, date)`
- `(user_id, product)`
- `(user_id, date, product)`

## ğŸš€ Como Executar

### PrÃ©-requisitos

- Docker e Docker Compose instalados
- Python 3.11+ (se executar localmente)

### OpÃ§Ã£o 1: Docker Compose (Recomendado)

1. Clone o repositÃ³rio:
```bash
git clone <repository-url>
cd marketdash
```

2. Crie um arquivo `.env` na raiz do projeto (opcional, valores padrÃ£o no docker-compose.yml):
```env
DATABASE_URL=postgresql://marketdash_user:marketdash_password@db:5432/marketdash_db
JWT_SECRET=your-secret-key-change-in-production-min-32-chars
JWT_ALGORITHM=HS256
JWT_EXPIRATION_HOURS=24
```

3. Execute o projeto:
```bash
docker compose up
```

4. Acesse a documentaÃ§Ã£o da API:
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

### OpÃ§Ã£o 2: ExecuÃ§Ã£o Local

1. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

2. Configure as variÃ¡veis de ambiente:
```bash
export DATABASE_URL=postgresql://user:password@localhost:5432/marketdash_db
export JWT_SECRET=your-secret-key-change-in-production-min-32-chars
```

3. Execute o servidor:
```bash
uvicorn app.main:app --reload
```

## ğŸ“¡ Endpoints da API

### ğŸ¥ Health Check

#### Verificar Status da AplicaÃ§Ã£o
```http
GET /health
```

**Resposta (healthy):**
```json
{
    "status": "healthy",
    "environment": "production",
    "timestamp": "2024-01-15T10:30:00Z",
    "database": "connected",
    "redis": "connected"
}
```

**Resposta (unhealthy):**
```json
{
    "status": "unhealthy",
    "environment": "production",
    "timestamp": "2024-01-15T10:30:00Z",
    "database": "disconnected",
    "redis": "not_configured"
}
```

**CÃ³digos de Status HTTP:**
- `200 OK`: AplicaÃ§Ã£o saudÃ¡vel (database conectado)
- `503 Service Unavailable`: AplicaÃ§Ã£o com problemas (database desconectado, etc.)

**O que o Health Check verifica:**
- ConexÃ£o com o banco de dados (PostgreSQL/Supabase)
- Status do Redis (se configurado)
- Ambiente atual (production/staging/development)
- Timestamp UTC da verificaÃ§Ã£o

### ğŸ” AutenticaÃ§Ã£o

#### Registrar Usuario
```http
POST /api/v1/auth/register
Content-Type: application/json

{
  "email": "usuario@example.com",
  "password": "senha123"
}
```

#### Login
```http
POST /api/v1/auth/login
Content-Type: application/x-www-form-urlencoded
#### Obter Usuario Atual
```http
GET /api/v1/auth/me
Authorization: Bearer {token}
```

#### Atualizar Usuario
```http
PUT /api/v1/auth/users/{user_id}
Authorization: Bearer {token}
```

#### Excluir Usuario
```http
DELETE /api/v1/auth/users/{user_id}
Authorization: Bearer {token}
```

email=usuario@example.com&password=senha123
```

**Resposta:**
```json
{
  "access_token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...",
  "token_type": "bearer"
}
```

### ğŸ“¥ Datasets

#### Upload de CSV
```http
POST /api/v1/datasets/upload
Authorization: Bearer {token}
Content-Type: multipart/form-data

file: [arquivo.csv]
```

**Formato esperado do CSV:**
```csv
date,product,revenue,cost,commission
2024-01-01,Produto A,1000.00,500.00,100.00
2024-01-02,Produto B,2000.00,800.00,200.00
```

**Colunas obrigatÃ³rias:**
- `date`: Data (formato: YYYY-MM-DD)
- `product`: Nome do produto
- `revenue`: Receita (nÃºmero)
- `cost`: Custo (nÃºmero)
- `commission`: ComissÃ£o (nÃºmero)

**Resposta:**
```json
{
  "id": 1,
  "user_id": 1,
  "filename": "dados.csv",
  "uploaded_at": "2024-01-15T10:30:00Z"
}
```

#### Listar Datasets
```http
GET /api/v1/datasets
Authorization: Bearer {token}
```

#### Obter Dataset Especifico
```http
GET /api/v1/datasets/{dataset_id}
Authorization: Bearer {token}
```

#### Linhas do Dataset Mais Recente
```http
GET /api/v1/datasets/latest/rows?limit=100&offset=0
Authorization: Bearer {token}
```

#### Todas as Linhas (paginado)
```http
GET /api/v1/datasets/all/rows?limit=100&offset=0
Authorization: Bearer {token}
```

#### Linhas de um Dataset
```http
GET /api/v1/datasets/{dataset_id}/rows
Authorization: Bearer {token}
```

#### Aplicar Ad Spend no Dataset Mais Recente
```http
POST /api/v1/datasets/latest/ad_spend
Authorization: Bearer {token}
```

#### Atualizar Dataset (Refresh)
```http
POST /api/v1/datasets/{dataset_id}/refresh
Authorization: Bearer {token}
```

> **Nota:** Este endpoint estÃ¡ preparado para integraÃ§Ã£o futura com API externa.

### ğŸ“Š Dashboard

#### Obter Dashboard Completo
```http
GET /api/v1/dashboard?start_date=2024-01-01&end_date=2024-01-31&product=Produto A
Authorization: Bearer {token}
```
### ğŸ’¸ Ad Spends

#### Listar Ad Spends
```http
GET /api/v1/ad_spends?limit=100&offset=0
Authorization: Bearer {token}
```

#### Criar Ad Spend
```http
POST /api/v1/ad_spends
Authorization: Bearer {token}
```

#### Criar Ad Spends em Lote
```http
POST /api/v1/ad_spends/bulk
Authorization: Bearer {token}
```

#### Atualizar Ad Spend
```http
PATCH /api/v1/ad_spends/{ad_spend_id}
Authorization: Bearer {token}
```

#### Excluir Ad Spend
```http
DELETE /api/v1/ad_spends/{ad_spend_id}
Authorization: Bearer {token}
```

#### Template de Importacao
```http
GET /api/v1/ad_spends/template
Authorization: Bearer {token}
```

### ğŸ”— Cakto

#### Webhook de Assinaturas
```http
POST /api/v1/cakto/webhook
```

**ParÃ¢metros de Query (todos opcionais):**
- `start_date`: Data inicial (YYYY-MM-DD)
- `end_date`: Data final (YYYY-MM-DD)
- `product`: Nome do produto (busca parcial)
- `min_value`: Valor mÃ­nimo
- `max_value`: Valor mÃ¡ximo

**Resposta:**
```json
{
  "kpis": {
    "total_revenue": 50000.00,
    "total_cost": 20000.00,
    "total_commission": 5000.00,
    "total_profit": 25000.00,
    "total_rows": 100
  },
  "period_aggregations": [
    {
      "period": "2024-01-01",
      "revenue": 1000.00,
      "cost": 500.00,
      "commission": 100.00,
      "profit": 400.00,
      "row_count": 5
    }
  ],
  "product_aggregations": [
    {
      "product": "Produto A",
      "revenue": 20000.00,
      "cost": 8000.00,
      "commission": 2000.00,
      "profit": 10000.00,
      "row_count": 50
    }
  ]
}
```

## ğŸ”’ SeguranÃ§a

- **AutenticaÃ§Ã£o JWT**: Todos os endpoints (exceto auth) requerem token JWT
- **Isolamento de Dados**: UsuÃ¡rios sÃ³ acessam seus prÃ³prios dados
- **ValidaÃ§Ã£o de Dados**: Pydantic valida todos os inputs
- **Hash de Senhas**: Bcrypt para armazenamento seguro de senhas

## ğŸ“Š CaracterÃ­sticas

### Processamento de CSV
- ValidaÃ§Ã£o automÃ¡tica de colunas obrigatÃ³rias
- NormalizaÃ§Ã£o de dados (datas, nÃºmeros)
- CÃ¡lculo automÃ¡tico de lucro (profit = revenue - cost - commission)
- Tratamento de erros e validaÃ§Ãµes robustas
- Suporte a mÃºltiplos encodings (UTF-8, Latin-1, ISO-8859-1)

### Analytics
- AgregaÃ§Ãµes SQL otimizadas
- Filtros flexÃ­veis por data, produto e valores
- KPIs calculados em tempo real
- AgregaÃ§Ãµes por perÃ­odo e por produto
- Queries otimizadas com Ã­ndices

### Arquitetura
- SeparaÃ§Ã£o de responsabilidades (Services, Models, Schemas)
- CÃ³digo escalÃ¡vel e manutenÃ­vel
- Preparado para integraÃ§Ã£o com APIs externas
- Base sÃ³lida para crescimento do SaaS

## ğŸ§ª Testes

Para executar testes (quando implementados):
```bash
pytest tests/
```

## ğŸ”„ MigraÃ§Ãµes de Banco de Dados

O projeto usa SQLAlchemy com criaÃ§Ã£o automÃ¡tica de tabelas. Para migraÃ§Ãµes mais avanÃ§adas, considere usar Alembic:

```bash
alembic init migrations
alembic revision --autogenerate -m "Initial migration"
alembic upgrade head
```

## ğŸ“ VariÃ¡veis de Ambiente

| VariÃ¡vel | DescriÃ§Ã£o | PadrÃ£o |
|----------|-----------|--------|
| `DATABASE_URL` | URL de conexÃ£o com PostgreSQL | - |
| `JWT_SECRET` | Chave secreta para JWT | - |
| `JWT_ALGORITHM` | Algoritmo JWT | HS256 |
| `JWT_EXPIRATION_HOURS` | Horas de expiraÃ§Ã£o do token | 24 |
| `CAKTO_WEBHOOK_SECRET` | Chave secreta para validaÃ§Ã£o de webhooks Cakto | - |

## ğŸš€ PrÃ³ximos Passos

- [ ] Implementar testes unitÃ¡rios e de integraÃ§Ã£o
- [ ] Adicionar rate limiting
- [ ] Implementar cache para queries frequentes
- [ ] Adicionar suporte a exportaÃ§Ã£o de dados
- [ ] IntegraÃ§Ã£o com API externa para atualizaÃ§Ã£o de dados
- [ ] Dashboard com mais mÃ©tricas e visualizaÃ§Ãµes
- [ ] Suporte a mÃºltiplos formatos de arquivo (Excel, JSON)
- [ ] Sistema de notificaÃ§Ãµes
- [ ] IntegraÃ§Ã£o com Supabase Auth

## ğŸ“„ LicenÃ§a

Este projeto Ã© proprietÃ¡rio.

## ğŸ‘¥ Contribuindo

Este Ã© um projeto interno. Para sugestÃµes e melhorias, entre em contato com a equipe de desenvolvimento.

---

**Desenvolvido com â¤ï¸ para anÃ¡lise de dados eficiente e escalÃ¡vel**

