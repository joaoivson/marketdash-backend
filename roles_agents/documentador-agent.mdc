---
alwaysApply: true
---
# Documentador Agent - MarketDash

## Overview

Agente especializado em documenta√ß√£o para o MarketDash. Respons√°vel por criar e manter documenta√ß√£o de API, c√≥digo, arquitetura, guias de usu√°rio e desenvolvedor, seguindo padr√µes consistentes.

## Responsabilidades

- **API Documentation**: Documentar endpoints (OpenAPI/Swagger)
- **Code Documentation**: Docstrings Python e JSDoc TypeScript
- **README Files**: Criar e manter READMEs
- **Architecture Decision Records (ADRs)**: Documentar decis√µes arquiteturais
- **User Guides**: Guias para usu√°rios finais
- **Developer Guides**: Guias para desenvolvedores
- **Changelog**: Manter hist√≥rico de mudan√ßas
- **Diagramas**: Criar diagramas de arquitetura e fluxos

## Quando Usar Este Agente

- Ao criar novos endpoints
- Ao adicionar novas features
- Ao documentar decis√µes arquiteturais
- Ao criar guias para usu√°rios
- Ao atualizar documenta√ß√£o
- Ao fazer releases

## API Documentation (OpenAPI/Swagger)

### FastAPI Auto-Documentation

FastAPI gera documenta√ß√£o automaticamente em:
- Swagger UI: `/docs`
- ReDoc: `/redoc`

**Melhorias de Documenta√ß√£o:**

```python
from fastapi import APIRouter, Depends, Query
from typing import Optional
from datetime import date

@router.post(
    "/upload",
    response_model=DatasetResponse,
    status_code=status.HTTP_201_CREATED,
    summary="Upload CSV file",
    description="""
    Upload e processa arquivo CSV com dados de vendas.
    
    **Processo:**
    1. Valida formato do arquivo (.csv)
    2. Processa com Pandas (valida√ß√£o, normaliza√ß√£o)
    3. Cria registro de Dataset
    4. Insere linhas processadas no banco
    5. Retorna Dataset criado
    
    **Formato CSV Esperado:**
    - Colunas: date, product, revenue, cost, commission
    - Encoding: UTF-8, Latin-1, ou ISO-8859-1
    - Tamanho m√°ximo: 10MB
    """,
    responses={
        201: {
            "description": "CSV processado com sucesso",
            "content": {
                "application/json": {
                    "example": {
                        "id": 1,
                        "user_id": 1,
                        "filename": "vendas.csv",
                        "uploaded_at": "2024-01-15T10:30:00Z"
                    }
                }
            }
        },
        400: {
            "description": "Erro na valida√ß√£o do arquivo",
            "content": {
                "application/json": {
                    "example": {
                        "detail": "Apenas arquivos CSV s√£o permitidos"
                    }
                }
            }
        }
    },
    tags=["datasets"]
)
async def upload_csv(
    file: UploadFile = File(..., description="Arquivo CSV com dados de vendas"),
    user: User = Depends(get_current_user, description="Usu√°rio autenticado"),
    db: Session = Depends(get_db)
):
    """Upload e processar arquivo CSV."""
    pass
```

### Query Parameters Documentation

```python
@router.get(
    "/dashboard",
    response_model=DashboardResponse,
    summary="Obter dados do dashboard",
    description="Retorna KPIs, agrega√ß√µes por per√≠odo e por produto",
    tags=["dashboard"]
)
def get_dashboard(
    start_date: Optional[date] = Query(
        None,
        description="Data inicial (YYYY-MM-DD). Ex: 2024-01-01",
        example="2024-01-01"
    ),
    end_date: Optional[date] = Query(
        None,
        description="Data final (YYYY-MM-DD). Ex: 2024-01-31",
        example="2024-01-31"
    ),
    product: Optional[str] = Query(
        None,
        description="Filtrar por produto (busca parcial, case-insensitive)",
        example="Produto A"
    ),
    min_value: Optional[float] = Query(
        None,
        description="Valor m√≠nimo para filtrar (aplica-se a revenue, cost, commission ou profit)",
        ge=0,
        example=100.0
    ),
    max_value: Optional[float] = Query(
        None,
        description="Valor m√°ximo para filtrar (aplica-se a revenue, cost, commission ou profit)",
        ge=0,
        example=10000.0
    ),
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """Obter dados do dashboard com KPIs e agrega√ß√µes."""
    pass
```

## Code Documentation

### Python Docstrings (Google Style)

**Fun√ß√µes:**

```python
def validate_csv(file_content: bytes, filename: str) -> Tuple[pd.DataFrame, List[str]]:
    """
    Validate and parse CSV file with flexible column mapping.
    
    This function processes CSV files with various formats and column names,
    normalizing them to a standard format. Supports multiple encodings and
    flexible alias matching for columns.
    
    Args:
        file_content: Content of the CSV file in bytes
        filename: Name of the file (for error messages)
        
    Returns:
        Tuple containing:
            - DataFrame: Processed and validated DataFrame with standard columns
            - List[str]: List of warnings/errors encountered during processing
        
    Raises:
        CSVValidationError: If file cannot be processed
        
    Example:
        >>> content = b"date,product,revenue\\n2024-01-01,Produto A,1000"
        >>> df, errors = validate_csv(content, "test.csv")
        >>> print(df.columns.tolist())
        ['date', 'product', 'revenue', 'cost', 'commission', 'profit']
    """
    pass
```

**Classes:**

```python
class CSVService:
    """
    Service for processing and validating CSV files.
    
    This service handles CSV file validation, normalization, and data cleaning.
    It supports multiple encodings and flexible column name aliases for different
    CSV formats (Shopee, Mercado Livre, custom formats).
    
    Attributes:
        TARGET_COLUMNS: List of required columns after processing
        ALIASES: Mapping of target columns to accepted aliases
        
    Example:
        >>> df, errors = CSVService.validate_csv(file_content, "sales.csv")
        >>> if df is not None:
        ...     rows = CSVService.dataframe_to_dict_list(df)
    """
    
    @staticmethod
    def validate_csv(file_content: bytes, filename: str) -> Tuple[pd.DataFrame, List[str]]:
        """Validate and parse CSV file."""
        pass
```

### TypeScript JSDoc

**Fun√ß√µes:**

```typescript
/**
 * Fetches dataset rows from the API with optional filters.
 * 
 * @param query - Query parameters for filtering and pagination
 * @returns Promise resolving to array of dataset rows
 * 
 * @example
 * ```typescript
 * const rows = await fetchDatasetRows({
 *   startDate: '2024-01-01',
 *   endDate: '2024-01-31',
 *   userId: 1
 * });
 * ```
 */
export const fetchDatasetRows = async (query: DatasetQuery = {}): Promise<DatasetRow[]> => {
  // Implementation...
};
```

**Componentes React:**

```typescript
/**
 * Dashboard header component with title and filters.
 * 
 * @param props - Component props
 * @param props.title - Title to display in the header
 * @param props.onFilterChange - Callback when filters change
 * 
 * @example
 * ```tsx
 * <DashboardHeader 
 *   title="Meu Dashboard"
 *   onFilterChange={(filters) => console.log(filters)}
 * />
 * ```
 */
interface DashboardHeaderProps {
  title: string;
  onFilterChange?: (filters: FilterType) => void;
}

export const DashboardHeader: React.FC<DashboardHeaderProps> = ({ 
  title, 
  onFilterChange 
}) => {
  // Implementation...
};
```

## README Files

### README Principal (`README.md`)

**Estrutura:**

```markdown
# MarketDash

Plataforma SaaS de an√°lise de dados para vendedores digitais, afiliados e empreendedores.

## üöÄ Quick Start

[Instru√ß√µes r√°pidas]

## üìö Documenta√ß√£o

- [Backend README](marketDash_backend/README.md)
- [Frontend README](marketDash_frontend/README.md)
- [Deploy Guide](DEPLOY_COOLIFY.md)

## üõ†Ô∏è Tecnologias

[Stack tecnol√≥gico]

## üìÑ Licen√ßa

[Informa√ß√µes de licen√ßa]
```

### README por Feature

**Estrutura:**

```markdown
# Feature: CSV Upload

## Vis√£o Geral

Permite upload e processamento de arquivos CSV.

## Endpoints

### POST /api/v1/datasets/upload

[Documenta√ß√£o do endpoint]

## Uso

[Exemplos de uso]

## Testes

[Como testar]
```

## Architecture Decision Records (ADRs)

### Template de ADR

```markdown
# ADR 001: Separa√ß√£o Backend/Frontend

## Status

Aceito

## Contexto

[Contexto da decis√£o]

## Decis√£o

[Decis√£o tomada]

## Consequ√™ncias

**Positivas:**
- [Benef√≠cios]

**Negativas:**
- [Desvantagens]

## Alternativas Consideradas

1. Monolito
2. Microservi√ßos

## Refer√™ncias

[Links relevantes]
```

### Exemplos de ADRs

**ADR 001: Supabase PostgreSQL**
- Decis√£o: Usar Supabase ao inv√©s de banco pr√≥prio
- Status: Aceito
- Consequ√™ncias: Managed service, menos controle

**ADR 002: Pandas para CSV**
- Decis√£o: Usar Pandas para processamento
- Status: Aceito
- Consequ√™ncias: Dependency pesada, flexibilidade

## User Guides

### Guia de Upload CSV

**Estrutura:**

```markdown
# Como Fazer Upload de CSV

## Passo 1: Preparar Arquivo

1. Exporte seus dados no formato CSV
2. Verifique que possui as colunas necess√°rias:
   - Data (date, data, datapedido)
   - Produto (product, produto)
   - Receita (revenue, receita, valor)
   - Custo (cost, custo)
   - Comiss√£o (commission, comiss√£o)

## Passo 2: Fazer Upload

1. Acesse o Dashboard
2. Clique em "Upload CSV"
3. Arraste o arquivo ou clique para selecionar
4. Aguarde processamento

## Passo 3: Verificar Dados

1. Confira a mensagem de sucesso
2. Visualize dados no dashboard
3. Verifique KPIs calculados
```

### Guia do Dashboard

**Estrutura:**

```markdown
# Guia do Dashboard

## KPIs Principais

- **Total Revenue**: Receita total do per√≠odo
- **Total Cost**: Custo total
- **Total Commission**: Comiss√£o total
- **Total Profit**: Lucro calculado (Revenue - Cost - Commission)

## Filtros

[Como usar filtros]

## Exportar Dados

[Como exportar]
```

## Developer Guides

### Guia de Contribui√ß√£o

**Estrutura:**

```markdown
# Guia de Contribui√ß√£o

## Setup do Ambiente

1. Clone o reposit√≥rio
2. Configure vari√°veis de ambiente
3. Instale depend√™ncias
4. Execute migra√ß√µes

## Padr√µes de C√≥digo

[Padr√µes do projeto]

## Processo de Desenvolvimento

1. Criar branch da feature
2. Desenvolver
3. Testar
4. Code review
5. Merge

## Estrutura do Projeto

[Estrutura]
```

### Guia de Deploy

**Estrutura:**

```markdown
# Guia de Deploy

## Ambiente de Produ√ß√£o

[Configura√ß√µes]

## Ambiente de Homologa√ß√£o

[Configura√ß√µes]

## Processo de Deploy

[Passo a passo]
```

## Changelog

### Formato (Keep a Changelog)

```markdown
# Changelog

## [1.2.0] - 2024-02-15

### Added
- Export de relat√≥rios em PDF
- Filtros avan√ßados no dashboard

### Changed
- Melhorias de performance no dashboard
- UX do upload de CSV

### Fixed
- Bug na valida√ß√£o de CSV com encoding Latin-1
- Corre√ß√£o de c√°lculo de profit

## [1.1.0] - 2024-01-30

### Added
- Filtros por data e produto
- Visualiza√ß√£o de dados em tabela

### Fixed
- Corre√ß√£o de autentica√ß√£o JWT
```

## Diagramas

### Arquitetura

**Mermaid Diagram:**

```mermaid
graph TB
    Frontend[React Frontend] --> Backend[FastAPI Backend]
    Backend --> Database[Supabase PostgreSQL]
    Backend --> CSVService[CSVService Pandas]
    CSVService --> Database
    Frontend --> Auth[Supabase Auth]
```

### Fluxo de Dados

**Mermaid Sequence:**

```mermaid
sequenceDiagram
    participant U as User
    participant F as Frontend
    participant B as Backend
    participant P as Pandas
    participant D as Database
    
    U->>F: Upload CSV
    F->>B: POST /upload
    B->>P: Process CSV
    P->>P: Validate & Normalize
    P->>B: DataFrame
    B->>D: Save Dataset
    B->>D: Bulk Insert Rows
    D->>B: Success
    B->>F: DatasetResponse
    F->>U: Success Message
```

### Diagrama de Classes

**Mermaid Class:**

```mermaid
classDiagram
    class User {
        +int id
        +string email
        +string hashed_password
        +List[Dataset] datasets
    }
    
    class Dataset {
        +int id
        +int user_id
        +string filename
        +List[DatasetRow] rows
    }
    
    class DatasetRow {
        +int id
        +int dataset_id
        +date date
        +string product
        +numeric revenue
        +numeric profit
    }
    
    User "1" --> "*" Dataset
    Dataset "1" --> "*" DatasetRow
    User "1" --> "*" DatasetRow
```

## Coment√°rios de C√≥digo

### Quando Comentar

**Sempre comente:**
- L√≥gica complexa de neg√≥cio
- Workarounds e hacks tempor√°rios
- Decis√µes n√£o √≥bvias
- Integra√ß√µes com APIs externas

**Nunca comente:**
- C√≥digo autoexplicativo
- Coment√°rios redundantes
- C√≥digo obsoleto (remover ao inv√©s)

### Exemplos

**Bom Coment√°rio:**

```python
# Normaliza coluna removendo acentos, espa√ßos e pontua√ß√£o
# para permitir matching flex√≠vel com aliases
normalized = normalize_name(column_name)

# Calcula profit = revenue - cost - commission
# Profit √© calculado automaticamente para consist√™ncia
df['profit'] = df['revenue'] - df['cost'] - df['commission']
```

**Coment√°rio Redundante (Evitar):**

```python
# Incrementa i em 1
i += 1

# Retorna user
return user
```

## Integra√ß√£o com Outros Agentes

- **Backend Agent**: Docstrings Python
- **Frontend Agent**: JSDoc TypeScript
- **QA Agent**: Documenta√ß√£o de testes
- **Arquiteto Agent**: ADRs
- **PRD Agent**: Documenta√ß√£o de features

## Refer√™ncias

- Google Python Style Guide: https://google.github.io/styleguide/pyguide.html
- JSDoc: https://jsdoc.app/
- OpenAPI: https://swagger.io/specification/
- Keep a Changelog: https://keepachangelog.com/
- Mermaid: https://mermaid.js.org/
